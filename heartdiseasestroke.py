# -*- coding: utf-8 -*-
"""HeartDiseaseStroke.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14rfwPCDlLLbRkSVjSqIFZMusEMJTa9HN

# Heart Disease
"""

# import các thư viện cơ bản
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from google.colab import files

# Kết nối Google Drive
from google.colab import drive
drive.mount('/content/drive/')

# Load dataset từ Google Drive
df = pd.read_csv('/content/drive/MyDrive/Heart_Disease_Prediction/heart_disease.csv')

# Xem 5 dòng đầu tập dữ liệu
df.head(5)

# Xem 5 dòng cuối dữ liệu
df.tail(5)

"""## Xử lý dữ liệu"""

# Xem các thuộc tính
df.columns

"""Do thuộc tính education (trình độ học vấn) không liên quan đến vấn đề bệnh tim hay không nên sẽ loại bỏ thuộc tính này"""

# Loại bỏ cột education
df.drop(columns = ['education'], inplace = True)

# Kiểm tra các loại dữ liệu của các thuộc tính, số lượng giá trị, mức sử dụng bộ nhớ, v.v.
df.info()

# Kiểm tra định dạng của tập dữ liệu, hàng, cột và các giá trị bị thiếu
print(f'Số dòng trên tập dữ liệu: {df.shape[0]}')
print(f'Số cột trên tập dữ liệu:: {df.shape[1]}')
print(f'Tổng số giá trị trên tập dữ liệu: {df.count().sum()}')
print(f'Tổng số giá trị bị thiếu: {sum(df.isna().sum())}')

## Xác định số lượng giá trị null theo thuộc tính
pd.isna(df).sum()[pd.isna(df).sum() > 0]

## Tiến hành loại bỏ giá trị null

## Giá trị null trong các biến số
df.glucose.fillna(df.glucose.median(),inplace = True)
df.cigsPerDay.fillna(df.cigsPerDay.median(),inplace = True)
df.totChol.fillna(df.totChol.median(),inplace = True)
df.BMI.fillna(df.BMI.median(),inplace = True)
df.heartRate.fillna(df.heartRate.median(),inplace = True)

## Giá trị thiếu trong các biến phân loại
df.BPMeds = df.BPMeds.fillna(df.BPMeds.mode().iloc[0])

## Kiểm tra xem các giá trị null đã bị xóa hay chưa sau khi xử lý chúng
pd.isna(df).sum()[pd.isna(df).sum() > 0]

## Kiểm tra xem các giá trị null đã bị xóa hay chưa sau khi xử lý chúng
df.info()

df['Heart_ stroke'].value_counts()

## Let's have a broader look at Heart Disease, the target variable in our analysis

sns.set(rc={'axes.facecolor':'none','axes.grid':False,'xtick.labelsize':9,'ytick.labelsize':9, 'figure.autolayout':True})
my_col = ('#c7e9b4', '#EEE8AA')

plt.figure(figsize=(6,4))

## Heart Stroke Cases (in Units)

plt.subplot(1,2,1)

plt.title('Heart Stroke Cases (in Units)', fontdict={'fontsize':9})
ax = sns.countplot(x="Heart_ stroke", data=df, palette=my_col, order=df['Heart_ stroke'].value_counts().index)

for p in ax.patches:
   ax.annotate('{:.0f}'.format(p.get_height()), (p.get_x()+0.30, p.get_height()+8))

## Heart Stroke Cases (in %)

plt.subplot(1,2,2)
plt.title('Heart Stroke Cases (in %)', fontdict={'fontsize':9})
df['Heart_ stroke'].value_counts().plot(kind='pie', colors=my_col, legend=None, ylabel='', autopct='%1.1f%%')
plt.savefig("count_class.jpeg", format='jpeg', dpi=100)
files.download('count_class.jpeg') 
plt.show()

"""Nhận xét:
1.   Bộ dữ liệu bị mất cân bằng do số trường hợp đột quỵ tim thấp hơn nhiều so với 
trường hợp không bị đột quy tim (644 so với 3594)
2.   Về tỷ lệ phần trăm, các trường hợp đột quỵ tim chỉ chiếm khoảng 15% tổng số trường hợp.


"""

## Let's have a look at the distribtuion in numerical features through histogram and box-whisker plots

sns.set(rc={'axes.facecolor':'none','axes.grid':False,'xtick.labelsize':14,'ytick.labelsize':14, 'figure.autolayout':True})
plt.figure(figsize=(16,22))

## Age of the Individual

plt.subplot(8,2,1)
plt.title('Age of the Individual : Histogram', fontdict={'fontsize':15})
sns.distplot(df.age, color='#c7e9b4', kde_kws={'linewidth':2,'color':'r'})
plt.subplot(8,2,2)
plt.title('Age of the Individual : Box & Whisker Plot', fontdict={'fontsize':15})
sns.boxplot(df.age, orient="h", color='#EEE8AA')

## Cigarettes / Day

plt.subplot(8,2,3)
plt.title('Cigarettes / Day: Histogram', fontdict={'fontsize':15})
sns.distplot(df.cigsPerDay, color="#c7e9b4", kde_kws={'linewidth':2,'color':'r'})
plt.subplot(8,2,4)
plt.title('Cigarettes / Day: Box & Whisker Plot', fontdict={'fontsize':15})
sns.boxplot(df.cigsPerDay, orient="h", color="#EEE8AA")

## Cholesterol Levels

plt.subplot(8,2,5)
plt.title('Total Cholesterol Levels: Histogram', fontdict={'fontsize':15})
sns.distplot(df.totChol, color="#c7e9b4", kde_kws={'linewidth':2,'color':'r'})
plt.subplot(8,2,6)
plt.title('Total Cholesterol Levels: Box & Whisker Plot', fontdict={'fontsize':15})
sns.boxplot(df.totChol, orient="h", color="#EEE8AA")

## Systolic Blood Pressure

plt.subplot(8,2,7)
plt.title('BP (sys) : Histogram', fontdict={'fontsize':15})
sns.distplot(df.sysBP, color="#c7e9b4", kde_kws={'linewidth':2,'color':'r'})
plt.subplot(8,2,8)
plt.title('BP (sys): Box & Whisker Plot', fontdict={'fontsize':15})
sns.boxplot(df.sysBP, orient="h", color="#EEE8AA")

## Diastolic Blood Pressure

plt.subplot(8,2,9)
plt.title('BP (dia) : Histogram', fontdict={'fontsize':15})
sns.distplot(df.diaBP, color="#c7e9b4", kde_kws={'linewidth':2,'color':'r'})
plt.subplot(8,2,10)
plt.title('BP (dia): Box & Whisker Plot', fontdict={'fontsize':15})
sns.boxplot(df.diaBP, orient="h", color="#EEE8AA")

## BMI

plt.subplot(8,2,11)
plt.title('BMI : Histogram', fontdict={'fontsize':15})
sns.distplot(df.BMI, color="#c7e9b4", kde_kws={'linewidth':2,'color':'r'})
plt.subplot(8,2,12)
plt.title('BMI : Box & Whisker Plot', fontdict={'fontsize':15})
sns.boxplot(df.BMI, orient="h", color="#EEE8AA")

## Heart Rate

plt.subplot(8,2,13)
plt.title('Heart Rate : Histogram', fontdict={'fontsize':15})
sns.distplot(df.heartRate, color="#c7e9b4", kde_kws={'linewidth':2,'color':'r'})
plt.subplot(8,2,14)
plt.title('Heart Rate : Box & Whisker Plot', fontdict={'fontsize':15})
sns.boxplot(df.heartRate, orient="h", color="#EEE8AA")

## Glucose

plt.subplot(8,2,15)
plt.title('Glucose : Histogram', fontdict={'fontsize':15})
sns.distplot(df.glucose, color="#c7e9b4", kde_kws={'linewidth':2,'color':'r'})
plt.subplot(8,2,16)
plt.title('Glucose : Box & Whisker Plot', fontdict={'fontsize':15})
sns.boxplot(df.glucose, orient="h", color="#EEE8AA");
plt.savefig("histogram and box-whisker plots.jpeg", format='jpeg', dpi=100)
files.download('histogram and box-whisker plots.jpeg') 
plt.show()

"""Nhận xét

1. Có thể thấy một số thuộc tính (trên thực tế, gần như tất cả) có ngoại lệ.
2. Thuộc tính glucose có số lượng ngoại lệ cao hơn
3. Các thuộc tính Total Cholesteron, BMI và Glucose có phân bố hình chuông (bình thường).


"""

## Now let's understand the impact of a combination of two numerical variables on Heart Stroke occurence

sns.set(rc={'axes.facecolor':'none','axes.grid':False,'xtick.labelsize':14,'ytick.labelsize':14, 'figure.autolayout':True})
plt.subplots(figsize=(16,20))
my_pal = ("#40E0D0", "#F4A460")

plt.subplot(5,2,1)
plt.title('Heart_ stroke by Age & Cigarettes / Day', fontdict={'fontsize':15})
sns.scatterplot(x='age', y='cigsPerDay', hue='Heart_ stroke', palette=my_pal, data=df)
plt.legend(bbox_to_anchor=(1.02, 1), loc='best', borderaxespad=0)

plt.subplot(5,2,2)
plt.title('Heart_ stroke by Age & Cholesterol', fontdict={'fontsize':15})
sns.scatterplot(x='age', y='totChol', hue='Heart_ stroke', palette=my_pal, data=df)
plt.legend(bbox_to_anchor=(1.02, 1), loc='best', borderaxespad=0)

plt.subplot(5,2,3)
plt.title('Heart_ stroke by Age & Systolic BP', fontdict={'fontsize':15})
sns.scatterplot(x='age', y='sysBP', hue='Heart_ stroke', palette=my_pal, data=df)
plt.legend(bbox_to_anchor=(1.02, 1), loc='best', borderaxespad=0)

plt.subplot(5,2,4)
plt.title('Heart_ stroke by Age & Diastolic BP', fontdict={'fontsize':15})
sns.scatterplot(x='age', y='diaBP', hue='Heart_ stroke', palette=my_pal, data=df)
plt.legend(bbox_to_anchor=(1.02, 1), loc='best', borderaxespad=0)

plt.subplot(5,2,5)
plt.title('Heart_ stroke by Age & BMI', fontdict={'fontsize':15})
sns.scatterplot(x='age', y='BMI', hue='Heart_ stroke', palette=my_pal, data=df)
plt.legend(bbox_to_anchor=(1.02, 1), loc='best', borderaxespad=0)

plt.subplot(5,2,6)
plt.title('Heart_ stroke by Age  & glucose', fontdict={'fontsize':15})
sns.scatterplot(x='age', y='glucose', hue='Heart_ stroke', palette=my_pal, data=df)
plt.legend(bbox_to_anchor=(1.02, 1), loc='best', borderaxespad=0)

plt.subplot(5,2,7)
plt.title('Heart_ stroke by Age  & Heart Rate', fontdict={'fontsize':15})
sns.scatterplot(x='age', y='heartRate', hue='Heart_ stroke', palette=my_pal, data=df)
plt.legend(bbox_to_anchor=(1.02, 1), loc='best', borderaxespad=0)

plt.subplot(5,2,8)
plt.title('Heart_ stroke by Cholesterol & Cigarettes / Day', fontdict={'fontsize':15})
sns.scatterplot(x='totChol', y='cigsPerDay', hue='Heart_ stroke', palette=my_pal, data=df)
plt.legend(bbox_to_anchor=(1.02, 1), loc='best', borderaxespad=0)

plt.subplot(5,2,9)
plt.title('Heart_ stroke by Systolic BP & Diastolic BP', fontdict={'fontsize':15})
sns.scatterplot(x='sysBP', y='diaBP', hue='Heart_ stroke', palette=my_pal, data=df)
plt.legend(bbox_to_anchor=(1.02, 1), loc='best', borderaxespad=0)

plt.show()

"""Nhận xét:
1. Không có nhiều mối tương quan giữa hầu hết các tính năng số và biến mục tiêu (đột quỵ tim).
2. HA tâm trương và HA tâm thu cho thấy một số mức độ tương quan. Và trong các tính năng còn lại, không có bất kỳ mối tương quan rõ ràng nào.
3. Nói chung, người ta nói rằng cholesterol và hút thuốc có mối tương quan trực tiếp với bệnh tim và đột quỵ tim, nhưng từ dữ liệu hiện tại, rất khó để thấy mối tương quan chặt chẽ như vậy.
"""

## Tiến hành nhóm các thuộc tính số & thuộc tính phân loại

num_df = df[['age', 'cigsPerDay', 'totChol', 'sysBP', 'diaBP', 'BMI', 'heartRate', 'glucose']] 
cat_df = df[['Gender', 'diabetes', 'BPMeds', 'prevalentStroke', 'prevalentHyp']]

## Thư viện hỗ trợ xử lý dữ liệu
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import MinMaxScaler,StandardScaler

## Chuyển đổi các dữ liệu chữ thành số

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder ()

#select ctegorical columns 
cat_df = df.select_dtypes(exclude=["int", "float"])

for i in cat_df:
    cat_df[i] = le.fit_transform(df[i])

#joining the data to the numeric data
num_df = df.select_dtypes(include=['int', 'float'])
main_df = pd.concat([num_df, cat_df], axis=1)
main_df.head(5)

##  Scaling the Data 

## For features with normal distribution, we use Standardisation with StandardScaler
## For features with skewed distribution, we use Normalisation with MinMaxscaler

## So first we'll have a glance at skewness of features before proceeding with scaling
df.skew(axis = 0)

## Now we continue with scaling process
minmaxsca = MinMaxScaler() # Normalization
stdsca = StandardScaler() # Standardization

main_df['age'] = stdsca.fit_transform(main_df[['age']])
main_df['prevalentHyp'] = stdsca.fit_transform(main_df[['prevalentHyp']])
main_df['totChol'] = stdsca.fit_transform(main_df[['totChol']])
main_df['diaBP'] = stdsca.fit_transform(main_df[['diaBP']])
main_df['BMI'] = stdsca.fit_transform(main_df[['BMI']])
main_df['heartRate'] = stdsca.fit_transform(main_df[['heartRate']])

main_df['cigsPerDay'] = minmaxsca.fit_transform(main_df[['cigsPerDay']])
main_df['BPMeds'] = minmaxsca.fit_transform(main_df[['BPMeds']])
main_df['diabetes'] = minmaxsca.fit_transform(main_df[['diabetes']])
main_df['sysBP'] = minmaxsca.fit_transform(main_df[['sysBP']])
main_df['glucose'] = minmaxsca.fit_transform(main_df[['glucose']])
main_df.head()

"""Do dữ liệu đang bị mất cân bằng nên ta sẽ sử dụng kỹ thuật Oversampling
Oversampling trong học máy (machine learning) là một kỹ thuật để thay đổi các lớp (class) của dữ liệu không bằng nhau để tạo ra các tập dữ liệu cân bằng (balanced dataset). 
Kỹ thuật này cố gắng tăng kích thước của các mẫu (sample) hiếm để tạo ra sự cân bằng khi dữ liệu không đủ.
"""

from sklearn.utils import resample

# separate minority and majority classes
not_heart_stroke= main_df[(main_df['Heart_ stroke'] == 0)]
heart_stroke = main_df[(main_df['Heart_ stroke'] == 1)]

# upsample minority
heart_stroke_upsampled = resample(heart_stroke,
                          replace=True, # sample with replacement
                          n_samples=len(not_heart_stroke), # match number in majority class
                          random_state=27) # reproducible results

# combine majority and upsampled minority
upsampled = pd.concat([not_heart_stroke, heart_stroke_upsampled])

# check new class counts
upsampled['Heart_ stroke'].value_counts()

# Xem lại thông tin
upsampled.head()

## Kiểm tra mối tương quan giữa các thuộc tính với biên mục tiêu
corr_matrix = upsampled.corr()
corr_matrix['Heart_ stroke'].sort_values(ascending=False)

#Visualize mô hình thể hiện mối tương quan giữa các thuộc tính
plt.figure(figsize=(14,12))
sns.heatmap(upsampled.corr(),linewidths=.1,cmap="YlGnBu", annot=True, annot_kws={"size": 8})
plt.yticks(rotation=0);
plt.savefig("corr.png", format='png', dpi=100, bbox_inches='tight')
files.download('corr.png') 
plt.show()

# Segregating the Dependent Variable in Y-axis and Independent Variables in X-axis

X = upsampled.drop(columns=["Heart_ stroke"])
y = upsampled["Heart_ stroke"]

## Scaling the data
scaler = StandardScaler()
X_scaled=scaler.fit_transform(X)

## Splitting the Data
from sklearn.model_selection import train_test_split
## We split the data into train & test sets in 80:20 ratio
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=0, stratify=y)

print('='*34, '\n', f'\033[94mTrain data & Test data shapes', '\n', f'\033[94m '*14, f'\033[94mX            y')
print('='*34, '\n', f'\033[94mTrain data | ', X_train.shape, y_train.shape, '\n', f'\033[94mTest data  | ', X_test.shape, y_test.shape)

from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, auc, roc_curve
from sklearn.model_selection import cross_val_predict, cross_val_score

"""# Decision Tree"""

from sklearn.tree import DecisionTreeClassifier as DT
dt = DT(criterion='entropy',random_state=42)
dt.fit(X_train, y_train)

y_pred_dt = dt.predict(X_test)

from sklearn.model_selection import cross_val_predict, cross_val_score

print("TEST RESULTS:\n")
#Report
print('Decision Tree Classifier Report:\n\n{}\n'.format(classification_report(y_test, y_pred_dt)))
res = cross_val_score(dt, X_test, y_test, cv=10, n_jobs=-1, scoring='accuracy')
#Độ chính xác trung bình
print('Average Accuracy:\t{0:.4f}\n'.format((res.mean())))
#Độ lệch chuẩn
print('Standard Deviation:\t{0:.4f}\n'.format(res.std()))
#Ma trận hỗn hợp
print('Confusion Matrix:\n{}\n'.format(confusion_matrix(y_test,dt.predict(X_test))))
#Điểm chính xác
print("Accuracy Score:\t\t{}%".format(round(dt.score(X_test, y_test)*100, 2)))

#Visualize Confusion Matrix (Ma trận hỗn hợp)
cfm_dt = confusion_matrix(y_test, y_pred_dt)
x_axis_labels = ["Disease_Stroke", "No_Disease_Stroke"]
y_axis_labels = ["Disease_Stroke", "No_Disease_Stroke"]

f, ax = plt.subplots(figsize =(6,6))
sns.heatmap(cfm_dt, annot = True, linewidths=0.2, linecolor="black", fmt = ".0f", ax=ax, xticklabels=x_axis_labels, yticklabels=y_axis_labels)
plt.title('Decision Tree Classifier confusion matrix')
plt.ylabel('TRUE LABEL')
plt.xlabel('PREDICTED LABEL');
plt.savefig("dtcm.png", format='png', dpi=150, bbox_inches='tight')
files.download('dtcm.png')
plt.show()
#(edible:0 poisonous:1)

from sklearn.tree import DecisionTreeClassifier, export_graphviz
import graphviz
Y_name = ['Diasease_Stroke','No_Diasease_Stroke']
dot_data = export_graphviz(dt, out_file=None, 
                         feature_names=X.columns,
                         class_names=Y_name, 
                         filled=True, rounded=True,  
                         special_characters=True)  
graph = graphviz.Source(dot_data)
graph.render(filename='DecisionTree.png')
files.download('DecisionTree.png')
graph

#Visualize biểu đồ thể hiện các đặc tính quan trọng trong bộ dữ liệu Mushrooms
features_list = X.columns.values
feature_importance = dt.feature_importances_
sorted_idx = np.argsort(feature_importance)

plt.figure(figsize=(6,5))
plt.barh(range(len(sorted_idx)), feature_importance[sorted_idx], align='center')
plt.yticks(range(len(sorted_idx)), features_list[sorted_idx])
plt.xlabel('Importance')
plt.title('Feature importances')
plt.draw()
plt.savefig("featureimp.png", format='png', dpi=100, bbox_inches='tight')
files.download('featureimp.png')
plt.show()

#Visualize đồ thị đường cong PR (Precision-Recall Curves)
precision, recall, thresholds = precision_recall_curve(y_test, y_pred_dt)
area = auc(recall, precision)
plt.figure()
plt.plot(recall, precision, label = 'Area Under Curve = %0.3f'% area)
plt.legend(loc = 'lower left')
plt.title('Precision-Recall Curves of Decision Tree')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.ylim([-0.1, 1.1])
plt.xlim([-0.1, 1.1])
plt.savefig("dtpr.png", format='png', dpi=150, bbox_inches='tight')
files.download('dtpr.png')
plt.show()

"""# Random Forest"""

from sklearn.ensemble import RandomForestClassifier as RF
rf = RF(n_estimators = 50, criterion = 'entropy', random_state = 42)
rf.fit(X_train, y_train)

y_pred_rf = rf.predict(X_test)

from sklearn.model_selection import cross_val_predict, cross_val_score

print("TEST RESULTS:\n")
#Report
print('Random Forest Classifier report:\n\n{}\n'.format(classification_report(y_test, y_pred_rf)))
res = cross_val_score(rf, X_test, y_test, cv=10, n_jobs=-1, scoring='accuracy')
#Độ chính xác trung bình
print('Average Accuracy:\t{0:.4f}\n'.format((res.mean())))
#Độ lệch chuẩn
print('Standard Deviation:\t{0:.4f}\n'.format(res.std()))
#Ma trận hỗn hợp
print('Confusion Matrix:\n{}\n'.format(confusion_matrix(y_test,rf.predict(X_test))))
#Điểm chính xác
print("Accuracy Score:\t\t{}%".format(round(rf.score(X_test, y_test)*100, 2)))

#Visualize Confusion Matrix (Ma trận hỗn hợp)
cfm_rf = confusion_matrix(y_test, y_pred_rf)

x_axis_labels = ["Edible", "Poisonous"]
y_axis_labels = ["Edible", "Poisonous"]

f, ax = plt.subplots(figsize =(6,6))
sns.heatmap(cfm_rf, annot = True, linewidths=0.2, linecolor="black", fmt = ".0f", ax=ax, xticklabels=x_axis_labels, yticklabels=y_axis_labels)
plt.title('Random Forest Classifier confusion matrix')
plt.ylabel('TRUE LABEL')
plt.xlabel('PREDICTED LABEL');
plt.savefig("rfcm.png", format='png', dpi=150, bbox_inches='tight')
files.download('rfcm.png')
plt.show()
#(edible:0 poisonous:1)

#Visualize đồ thị đường cong PR (Precision-Recall Curves)
precision, recall, thresholds = precision_recall_curve(y_test, y_pred_rf)
area = auc(recall, precision)
plt.figure()
plt.plot(recall, precision, label = 'Area Under Curve = %0.3f'% area)
plt.legend(loc = 'lower left')
plt.title('Precision-Recall Curves of Random Forest')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.ylim([-0.1, 1.1])
plt.xlim([-0.1, 1.1])
plt.savefig("rfpr.png", format='png', dpi=150, bbox_inches='tight')
files.download('rfpr.png')
plt.show()

# Visualize biểu đồ thể hiện các đặc tính quan trọng trong bộ dữ liệu Mushrooms
features_list = X.columns.values
feature_importance = rf.feature_importances_
sorted_idx = np.argsort(feature_importance)

plt.figure(figsize=(6,5))
plt.barh(range(len(sorted_idx)), feature_importance[sorted_idx], align='center')
plt.yticks(range(len(sorted_idx)), features_list[sorted_idx])
plt.xlabel('Importance')
plt.title('Feature importances')
plt.draw()
#plt.savefig("featureimp.png", format='png', dpi=100, bbox_inches='tight')
plt.show()

from sklearn.neighbors import KNeighborsClassifier as KNN
knn = KNN()
knn.fit(X_train,y_train)

y_pred_knn = knn.predict(X_test)

from sklearn.model_selection import cross_val_predict, cross_val_score

print("TEST RESULTS:\n")
#Report
print('K-Nearest Neighbors report:\n\n{}\n'.format(classification_report(y_test, y_pred_knn)))
res = cross_val_score(knn, X_test, y_test, cv=10, n_jobs=-1, scoring='accuracy')
#Độ chính xác trung bình
print('Average Accuracy:\t{0:.4f}\n'.format((res.mean())))
#Độ lệch chuẩn
print('Standard Deviation:\t{0:.4f}\n'.format(res.std()))
#Ma trận hỗn hợp
print('Confusion Matrix:\n{}\n'.format(confusion_matrix(y_test,knn.predict(X_test))))
#Điểm chính xác
print("Accuracy Score:\t\t{}%".format(round(knn.score(X_test, y_test)*100, 2)))

#Visualize Confusion Matrix (Ma trận hỗn hợp)
cfm_knn = confusion_matrix(y_test, y_pred_knn)

x_axis_labels = ["Edible", "Poisonous"]
y_axis_labels = ["Edible", "Poisonous"]

f, ax = plt.subplots(figsize =(6,6))
sns.heatmap(cfm_knn, annot = True, linewidths=0.2, linecolor="black", fmt = ".0f", ax=ax, xticklabels=x_axis_labels, yticklabels=y_axis_labels)
plt.title('K-Nearest Neighbors confusion matrix')
plt.ylabel('TRUE LABEL')
plt.xlabel('PREDICTED LABEL');
#plt.savefig("knncm.png", format='png', dpi=150, bbox_inches='tight')
plt.show()
#(edible:0 poisonous:1)

#Visualize đồ thị đường cong PR (Precision-Recall Curves)
precision, recall, thresholds = precision_recall_curve(y_test, y_pred_knn)
area = auc(recall, precision)
plt.figure()
plt.plot(recall, precision, label = 'Area Under Curve = %0.3f'% area)
plt.legend(loc = 'lower left')
plt.title('Precision-Recall Curves of K-Nearest Neighbors')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.ylim([-0.1, 1.1])
plt.xlim([-0.1, 1.1])
#plt.savefig("knnpr.png", format='png', dpi=150, bbox_inches='tight')
plt.show()

"""# ROC Curves"""

#Visualize mô hình ROC (Receiver Operating Characteristic) Curves - so sánh trực quan các mô hình phân loại
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score, accuracy_score

plt.figure(figsize=(12,9))
models = [
{
    'label': 'Decision Tree',
    'model': dt,
},
{
    'label': 'Random Forest',
    'model': rf,
},
#{
#    'label': 'K-Nearest Neighbors',
#    'model': knn,
#}
]

for m in models:
    model = m['model'] 
    model.fit(X_train, y_train) 
    y_pred=model.predict(X_test) 
    fpr, tpr, thresholds = roc_curve(y_test, model.predict_proba(X_test)[:,1])
    auc = roc_auc_score(y_test,model.predict(X_test))
    plt.plot(fpr, tpr, linestyle='-', linewidth=3, label='%s ROC (area = %0.2f)' % (m['label'], auc))

plt.plot([0, 1], [0, 1],'b--', linewidth=3)
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('1 - Specificity (False Positive Rate)', fontsize=15)
plt.ylabel('Sensitivity (True Positive Rate)', fontsize=15)
plt.title('Receiver Operating Characteristic (ROC)', fontsize=15)
plt.legend(loc="lower right", fontsize=14)
plt.savefig("roc_curves.png", format='png', dpi=100, bbox_inches='tight')
files.download('roc_curves.png')
plt.show()